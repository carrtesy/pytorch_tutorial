{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataloader.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1eKPoktadqR5a0UP9la8xtH02p6AehszL",
      "authorship_tag": "ABX9TyOnPSldyYLqrLyycAx/HzLr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dongminkim0220/pytorch_tutorial/blob/master/dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFrwZW86t66C"
      },
      "source": [
        "# dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJUpLe7VzTMP"
      },
      "source": [
        "PyTorch Tutorial 09 - Dataset and DataLoader - Batch Training\n",
        "\n",
        "https://www.youtube.com/watch?v=PXOzkkB5eH0&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=10\n",
        "\n",
        "PyTorch Tutorial 10 - Dataset Transforms\n",
        "\n",
        "https://www.youtube.com/watch?v=X_QOZEko5uE&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc2F9P_7uIiE"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkvZTXtIvhvK"
      },
      "source": [
        "file = \"/content/drive/MyDrive/pytorch intro/wine.csv\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frIokrETxurT"
      },
      "source": [
        "## dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3MuDni6ukYO"
      },
      "source": [
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "    # data loading\n",
        "    xy = np.loadtxt(file, delimiter=',', dtype = np.float32, skiprows = 1)\n",
        "    self.x = torch.from_numpy(xy[:, 1:])\n",
        "    self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # dataset[0]\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    # len(dataset)\n",
        "    return self.n_samples"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93hShSw0wraW"
      },
      "source": [
        "dataset = WineDataset()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBp9RfJnws_d"
      },
      "source": [
        "first_data = dataset[0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv2JKyK9wwuH"
      },
      "source": [
        "features, labels = first_data"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiE37NM9wy2l",
        "outputId": "21486c49-5606-4800-9c0a-6cebf2d0e129"
      },
      "source": [
        "features, labels"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
              "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
              "         1.0650e+03]), tensor([1.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0Revbulxz28"
      },
      "source": [
        "## dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr_J7TXRw0Z-"
      },
      "source": [
        "dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle = True, num_workers = 2)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-85I9Xt2xG8F"
      },
      "source": [
        "dataiter = iter(dataloader)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haCjxG8hxK6-"
      },
      "source": [
        "data = dataiter.next()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrkoT8htxNr9"
      },
      "source": [
        "features,labels = data"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lqXFYvExPQ9",
        "outputId": "3b1263f0-52e0-40a7-d680-2941525d2fd1"
      },
      "source": [
        "features, labels"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.3870e+01, 1.9000e+00, 2.8000e+00, 1.9400e+01, 1.0700e+02, 2.9500e+00,\n",
              "          2.9700e+00, 3.7000e-01, 1.7600e+00, 4.5000e+00, 1.2500e+00, 3.4000e+00,\n",
              "          9.1500e+02],\n",
              "         [1.3450e+01, 3.7000e+00, 2.6000e+00, 2.3000e+01, 1.1100e+02, 1.7000e+00,\n",
              "          9.2000e-01, 4.3000e-01, 1.4600e+00, 1.0680e+01, 8.5000e-01, 1.5600e+00,\n",
              "          6.9500e+02],\n",
              "         [1.4370e+01, 1.9500e+00, 2.5000e+00, 1.6800e+01, 1.1300e+02, 3.8500e+00,\n",
              "          3.4900e+00, 2.4000e-01, 2.1800e+00, 7.8000e+00, 8.6000e-01, 3.4500e+00,\n",
              "          1.4800e+03],\n",
              "         [1.3730e+01, 1.5000e+00, 2.7000e+00, 2.2500e+01, 1.0100e+02, 3.0000e+00,\n",
              "          3.2500e+00, 2.9000e-01, 2.3800e+00, 5.7000e+00, 1.1900e+00, 2.7100e+00,\n",
              "          1.2850e+03]]), tensor([[1.],\n",
              "         [3.],\n",
              "         [1.],\n",
              "         [1.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgGbvPjXxQnu"
      },
      "source": [
        "## training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq-ugX0Rx5jz"
      },
      "source": [
        "num_epochs = 2"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXa_qY3ax7sE"
      },
      "source": [
        "total_samples = len(dataset)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZFQFCEtx_hF"
      },
      "source": [
        "n_iterations = math.ceil(total_samples/4)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTKXR8pAyP31",
        "outputId": "4f2b679a-d814-4f35-99d3-06e0c1364f66"
      },
      "source": [
        "total_samples, n_iterations"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myyoKnGRyZdv",
        "outputId": "c51cca22-288a-4051-ec0b-dcab3c2c3c8d"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (input, labels) in  enumerate(dataloader):\n",
        "    # forward, backward, update\n",
        "    # ...\n",
        "\n",
        "    # check\n",
        "    if (i+1) % 5 == 0:\n",
        "      print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, input {input.shape}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1/2, step 5/45, input torch.Size([4, 13])\n",
            "epoch 1/2, step 10/45, input torch.Size([4, 13])\n",
            "epoch 1/2, step 15/45, input torch.Size([4, 13])\n",
            "epoch 1/2, step 20/45, input torch.Size([4, 13])\n",
            "epoch 1/2, step 25/45, input torch.Size([4, 13])\n",
            "epoch 1/2, step 30/45, input torch.Size([4, 13])\n",
            "epoch 1/2, step 35/45, input torch.Size([4, 13])\n",
            "epoch 1/2, step 40/45, input torch.Size([4, 13])\n",
            "epoch 1/2, step 45/45, input torch.Size([2, 13])\n",
            "epoch 2/2, step 5/45, input torch.Size([4, 13])\n",
            "epoch 2/2, step 10/45, input torch.Size([4, 13])\n",
            "epoch 2/2, step 15/45, input torch.Size([4, 13])\n",
            "epoch 2/2, step 20/45, input torch.Size([4, 13])\n",
            "epoch 2/2, step 25/45, input torch.Size([4, 13])\n",
            "epoch 2/2, step 30/45, input torch.Size([4, 13])\n",
            "epoch 2/2, step 35/45, input torch.Size([4, 13])\n",
            "epoch 2/2, step 40/45, input torch.Size([4, 13])\n",
            "epoch 2/2, step 45/45, input torch.Size([2, 13])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhY2m-eWy2jY"
      },
      "source": [
        "## Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPzXNrLozReE"
      },
      "source": [
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self, transform = None):\n",
        "    # data loading\n",
        "    xy = np.loadtxt(file, delimiter=',', dtype = np.float32, skiprows = 1)\n",
        "    self.x = xy[:, 1:]\n",
        "    self.y = xy[:, [0]] # n_samples, 1\n",
        "    self.n_samples = xy.shape[0]\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample = self.x[index], self.y[index]\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    # len(dataset)\n",
        "    return self.n_samples"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_v4-_gu0SvR"
      },
      "source": [
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gm3ZhRP0uaV"
      },
      "source": [
        "dataset = WineDataset(transform = ToTensor())"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EopUPHWy04Pe"
      },
      "source": [
        "first_data = dataset[0]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtLdjsV-06lV",
        "outputId": "5de4ad41-2b89-4b27-9c44-a0255fe760e3"
      },
      "source": [
        "features, labels, type(features), type(labels)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.3870e+01, 1.9000e+00, 2.8000e+00, 1.9400e+01, 1.0700e+02, 2.9500e+00,\n",
              "          2.9700e+00, 3.7000e-01, 1.7600e+00, 4.5000e+00, 1.2500e+00, 3.4000e+00,\n",
              "          9.1500e+02],\n",
              "         [1.3450e+01, 3.7000e+00, 2.6000e+00, 2.3000e+01, 1.1100e+02, 1.7000e+00,\n",
              "          9.2000e-01, 4.3000e-01, 1.4600e+00, 1.0680e+01, 8.5000e-01, 1.5600e+00,\n",
              "          6.9500e+02],\n",
              "         [1.4370e+01, 1.9500e+00, 2.5000e+00, 1.6800e+01, 1.1300e+02, 3.8500e+00,\n",
              "          3.4900e+00, 2.4000e-01, 2.1800e+00, 7.8000e+00, 8.6000e-01, 3.4500e+00,\n",
              "          1.4800e+03],\n",
              "         [1.3730e+01, 1.5000e+00, 2.7000e+00, 2.2500e+01, 1.0100e+02, 3.0000e+00,\n",
              "          3.2500e+00, 2.9000e-01, 2.3800e+00, 5.7000e+00, 1.1900e+00, 2.7100e+00,\n",
              "          1.2850e+03]]), tensor([[3.],\n",
              "         [2.]]), torch.Tensor, torch.Tensor)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6_5LyMk1XMF"
      },
      "source": [
        "class MulTransform:\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    inputs, target = sample\n",
        "    inputs *= self.factor\n",
        "    return inputs, target"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpuMh4oP1u8R"
      },
      "source": [
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P3PILs714ou"
      },
      "source": [
        "dataset = WineDataset(transform = composed)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9L9ZphX188t"
      },
      "source": [
        "first_data = dataset[0]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G7d7dFW1_dY"
      },
      "source": [
        "features, labels = first_data"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7FiSjA62EmM",
        "outputId": "3a2cb279-3182-4aad-befb-b2e636d5ed4d"
      },
      "source": [
        "features, labels, type(features), type(labels)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
              "         6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
              "         2.1300e+03]), tensor([1.]), torch.Tensor, torch.Tensor)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}